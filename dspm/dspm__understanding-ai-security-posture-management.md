# Understanding AI Security Posture Management
Source: https://help.zscaler.com/dspm/understanding-ai-security-posture-management
PDF: https://help.zscaler.com/pdf/com/en/1532203.pdf

Organizations are increasingly adopting generative AI (Gen AI) workloads in the public cloud to build enterprise-grade AI services that deliver faster, higher quality customer experiences and improve return on investment (ROI). These private Gen AI applications are not only built with managed AI platforms, such as AWS Bedrock and Azure Foundry, but also by deploying unknown and potentially risky AI models sourced from open-source AI repositories, like Hugging Face and Ollama.
To get the most out of these AI agents and tools, organizations need to share their data to make the responses customized to their scenarios. This can be done by tuning the AI model with organization-specific data, or by sharing the data as retrieval augmented generation (RAG). While sharing specific data with the AI models, it is possible that additional sensitive data might be shared either by mistake or by a malicious actor trying to poison the data. Misconfigurations of the AI service can also lead to unwanted data leaks through bad guardrails, agent exposure, usage of vulnerable AI packages, and more. All of these could result in significant data breaches leading to compliance violations under various legal and regulatory frameworks such as GDPR, HIPAA, etc.
AI Security Posture Management (AI-SPM) is a comprehensive strategy for securing AI systems by monitoring models, data, and infrastructure to identify and mitigate risks. Zscaler AI-SPM solution leverages the strengths of AI to sift through high volumes of enterprise data used for AI model training or model response with retrieval-augmented generation (RAG) and detect anomalies and potential risks such as sensitive data exposure, vulnerabilities, unauthorized access, and other security incidents. AI-SPM then correlates signals across data classification and discovery, data access paths, and potential exposure of sensitive data to AI, identifying potential vulnerabilities and misconfigurations to quickly detect hidden AI risks. Zscaler AI-SPM enables organizations to innovate safely with Gen AI, by preventing costly data breaches, legal penalties, and reputational damage stemming from unsecured AI data usage, while simultaneously improving control and visibility over their AI ecosystem.
The AI-SPM solution builds on the unified data security platform that powers Zscaler [Endpoint DLP](/zia/about-endpoint-dlp), inline-web, [SaaS Security](/zia/understanding-saas-security-posture-management-policy), and [data security posture management (DSPM)](/dspm/what-data-security-posture-management) solutions. It leverages the advanced data discovery and risk correlation engine built into DSPM and its intuitive graph UI and policy engine to deliver unparalleled visibility to AI risk and governance.
Key Features and Benefits
Organizations face significant challenges in balancing productivity and ensuring data security with AI adoption and controlling what AI can see and do with enterprise data. Zscaler AI-SPM provides the following benefits to help alleviate the challenges:
- **Data discovery and classification**: Discover and classify sensitive data that is stored in cloud environments by leveraging 200+ AI-based classifiers for accurate classification.
- **AI inventory**: Identify AI workloads and types (e.g., AI Agent, AI Model) and build effective inventory of all the AI components, and provide visibility into the AI software supply chain.
- **Enable secure and responsible AI adoption and innovation**: Help organizations adopt Gen AI workloads and leverage their benefits (faster services, quality customer experiences, ROI) without being hampered by overwhelming security and compliance fears.
- **Reduce hidden AI risks and vulnerabilities**: Provide visibility into AI workloads, untrusted AI models (e.g., Hugging Face), potential public exposure, misconfigurations, vulnerabilities, data oversharing and risky AI models having access to data.
- **Implement security policies**: Provide predefined policies that help prioritize and remediate these risks.
- **Mitigate data breaches and protect sensitive data**: Prevent accidental exposure of sensitive enterprise data (customer information, proprietary data, etc.) to AI resources, which could lead to significant and costly data breaches. This directly protects customer trust and brand reputation, and prevents financial losses associated with breach response.
- **Achieve AI governance and build trust**: Provide AI compliance reports on how organizations can align with NIST 600-1, facilitating AI governance and responsible AI adoption.
- **Ensure regulatory compliance**: Avoid severe financial penalties and legal repercussions (e.g., GDPR, HIPAA fines) that arise from noncompliance with data protection regulations when sensitive data is mishandled by AI applications.
- **Support Industry Benchmarks**: Support out-of-the-box AI-related benchmarks such as NIST AI 600-1 and EU AI Act that focus on AI service security.